# ğŸ† Contests Tracker  

ğŸ”— video demo :-  https://drive.google.com/file/d/1CNmlFxwUjBfUWUzQw5IqAe3lyD9tn77j/view?usp=sharing

## ğŸš€ Overview  
**Contests Tracker** is a fully automated system that:  
- ğŸ“… **Fetches live & past coding contests** from:  
  - **LeetCode API** ğŸŸ   
  - **Codeforces API** ğŸ”µ  
  - **CodeChef Scraper** (Requests & selenium) ğŸŸ£  
- ğŸ¥ **Scrapes and stores contest solution videos** from **TLE Eliminators YouTube Channel** using **Selenium**  
- ğŸ—„ **Stores past 3 months of contest data** in **MongoDB**  
- ğŸ”‘ **User Authentication** â€“ Login & Signup with JWT-based authentication  
- â­ **Bookmark Feature** â€“ Users can save favorite contests for quick access  
- ğŸ¤– **Runs automatically via Crontab** (No manual execution needed)  

---


---

## ğŸ“Œ Key Features  
âœ… **Live & Upcoming & Contests** â€“ Fetched using **LeetCode & Codeforces APIs ,codechef with  selenium **  
âœ… **Time Remaining for Contests** â€“ Displays countdown â³ until the contest starts.
âœ… **Past Contests Storage** â€“ Maintains **past 1 week  to  3 months** of contest data  with  video  solutions from tle  eliminators
âœ… **Youtube video  Solution Scraper** â€“ Fetches **TLE Eliminators** solution videos using **Selenium**  automatically
âœ… **Login & Signup** â€“ Secure authentication using JWT  
âœ… **Bookmark Contests** â€“ Users can save contests for quick access  and retrieve  it 
âœ… **Runs on Crontab** â€“ No need for manual execution  
âœ… **Separate Services** â€“ Backend, Crawler, and Frontend are independent  
âœ… **Dedicated Past Contests Fetcher** â€“ A separate module fetches and stores past contests from Codeforces, LeetCode, and CodeChef  

---

## ğŸ— **System Architecture**  

The project is designed as **three independent services** that interact only through the **MongoDB database**:  

### 1ï¸âƒ£ **Crawler (Python Implementation) ğŸ**  
- **Handles all contest & solution fetching**  
- Uses **Requests + BeautifulSoup** for **LeetCode, Codeforces, and CodeChef** contests  
- Uses **Selenium** for fetching **YouTube solutions**  
- **Runs automatically via Crontab** on the server (No direct interaction with backend)  
- Saves all fetched data directly into **MongoDB**  

### 2ï¸âƒ£ **Backend API (Node.js) ğŸŸ¢**  
- **Completely separate from the crawler**  
- Uses **Express.js** to serve contest & solution data  
- Handles **user authentication (JWT-based login & signup)**  
- Provides **bookmarking & user dashboard features**  
- Fetches contest data **directly from MongoDB** (No need to interact with the crawler)  

### 3ï¸âƒ£ **Frontend (React) âš›ï¸**  
- **Completely separate from backend & crawler**  
- Fetches contest & solution data via backend API  
- Provides **user authentication, bookmarking, and contest dashboard**  
- Uses **React hooks & state management** for a smooth experience  

### ğŸ›  **How They Communicate**  
- **Crawler â†’ MongoDB** â†’ Fetches contests, scrapes solutions, and stores them  
- **Backend â†’ MongoDB** â†’ Reads data & provides API access to the frontend  
- **Frontend â†’ Backend (API)** â†’ Fetches contest & user data via **REST APIs**  

### ğŸ“Œ **Key Separation Highlights**  
âœ… **Crawler is completely independent** â€“ It runs via **Crontab**, not triggered by backend requests  
âœ… **No direct connection** between backend and crawler â€“ Only **MongoDB** is shared  
âœ… **Fully automated system** â€“ No need for manual execution; everything is handled by **scheduled cron jobs**  

This ensures a **modular, scalable, and efficient system**, where each component runs **independently** and can be upgraded separately without affecting others! ğŸš€

----



## ğŸ›  Tech Stack  
- **Frontend:** âš›ï¸ React.js  
- **Backend:** ğŸŸ¢ Node.js (Express.js)  
- **Database:** ğŸ›¢ MongoDB  
- **APIs Used:**  
  - ğŸ“¡ **Codeforces API**  
  - ğŸ“¡ **LeetCode API (graph ql  queries)**  
- **Web Scraping:** ğŸŒ  
  - **Requests + BeautifulSoup** â†’ leetcode and  codechef  Contests  
  - **Selenium** â†’ YouTube Solution Videos  and codechef  contests
- **Authentication:** ğŸ”‘ JWT-based login & signup  
- **Automation:** â³ Cron Jobs (Crontab)  



## ğŸš€ How to Run  

### ğŸ **Run the Crawler (Python) â€“ Independent Module**  
The crawler runs separately, fetching contests & YouTube solutions. Just run it, and your database will be filled automatically! âœ…  


python3 crawler_main.py 

Or automate it with crontab

ğŸ”¹ Make sure to install dependencies:
pip install -r requirements.txt  

ğŸ”¹ Ensure Selenium WebDriver is installed for YouTube scraping.

you can run backend simply by going  into directory  setting up your  mongo  uri  and running  server.js 


## ğŸ¯ Challenges Faced & Solutions  

ğŸ”¹ **Rate Limits in APIs**: Used caching to avoid excessive requests  
ğŸ”¹ **Handling Dynamic Content**: Used Selenium for JavaScript-rendered pages  
ğŸ”¹ **Avoiding IP Blocks**: Implemented proxies & user-agents in scrapers  
ğŸ”¹ **Efficient Storage**: Used MongoDB for contest history  
ğŸ”¹ **Automating Everything**: Used Crontab for scheduled execution  

---

## ğŸ“¢ Future Improvements  

ğŸš€ **Add reminders & notifications** for upcoming contests  
ğŸš€ **Improve frontend UI** for better user experience  
ğŸš€ **Expand to more** competitive programming sites  
ğŸš€ **Optimize YouTube scraping** for better solution accuracy  



